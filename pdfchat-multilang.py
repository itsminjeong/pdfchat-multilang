import streamlit as st
from streamlit_chat import message
from langchain.embeddings.openai import OpenAIEmbeddings
from langchain.chat_models import ChatOpenAI
from langchain.chains import ConversationalRetrievalChain
from langchain.vectorstores import FAISS
from langchain.document_loaders import PyPDFLoader
from dotenv import load_dotenv
import tempfile
import os

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="PDF Chatbot", page_icon="ğŸ¤–")

# í™˜ê²½ ë³€ìˆ˜ ë¶ˆëŸ¬ì˜¤ê¸°
load_dotenv()
openai_api_key = os.getenv("OPENAI_API_KEY")

# ì–¸ì–´ ì„ íƒ UI ì¶”ê°€ (ì‚¬ì´ë“œë°”)
lang = st.sidebar.selectbox("Language / ì–¸ì–´ ì„ íƒ", ("í•œêµ­ì–´", "English"))

# ë‹¤êµ­ì–´ ë©”ì‹œì§€ ë”•ì…”ë„ˆë¦¬ ì •ì˜
messages = {
    "í•œêµ­ì–´": {
        "page_title": "PDF ê¸°ë°˜ GPT ì±—ë´‡",
        "page_markdown": "PDF íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê³  ììœ ë¡­ê²Œ ì§ˆë¬¸í•´ë³´ì„¸ìš”!",
        "file_uploader": "PDF íŒŒì¼ ì—…ë¡œë“œ",
        "input_label": "ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”:",
        "input_placeholder": "ì˜ˆ: 2í˜ì´ì§€ ìš”ì•½í•´ì¤˜",
        "send_button": "ë³´ë‚´ê¸°",
        "init_greeting_user": "ì•ˆë…•í•˜ì„¸ìš”!",
        "init_greeting_bot": "ì•ˆë…•í•˜ì„¸ìš”! ì—…ë¡œë“œí•œ ë¬¸ì„œì— ëŒ€í•´ ì§ˆë¬¸í•´ë³´ì„¸ìš”."
    },
    "English": {
        "page_title": "GPT-powered PDF Chatbot",
        "page_markdown": "Upload a PDF and ask questions freely!",
        "file_uploader": "Upload PDF file",
        "input_label": "Enter your question:",
        "input_placeholder": "e.g., Summarize page 2",
        "send_button": "Send",
        "init_greeting_user": "Hello!",
        "init_greeting_bot": "Hello! Ask me anything about the uploaded document."
    }
}

# ì„ íƒí•œ ì–¸ì–´ì— ë”°ë¥¸ ë©”ì‹œì§€ ë¶ˆëŸ¬ì˜¤ê¸°
msg = messages[lang]

# í˜ì´ì§€ ì œëª©ê³¼ ì„¤ëª… ì¶œë ¥
st.title(msg["page_title"])
st.markdown(msg["page_markdown"])

# PDF íŒŒì¼ ì—…ë¡œë“œ ë°›ê¸°
uploaded_file = st.sidebar.file_uploader(msg["file_uploader"], type="pdf")

# íŒŒì¼ ì—…ë¡œë“œê°€ ì™„ë£Œë˜ì—ˆì„ ë•Œ
if uploaded_file:
    # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
    with tempfile.NamedTemporaryFile(delete=False) as tmp_file:
        tmp_file.write(uploaded_file.getvalue())
        tmp_file_path = tmp_file.name

    # 1. PDF ë¬¸ì„œ ë¡œë“œ
    loader = PyPDFLoader(tmp_file_path)
    data = loader.load()

    # 2. ë¬¸ì„œ ì„ë² ë”© í›„ ë²¡í„° ì €ì¥ì†Œ ìƒì„±
    embeddings = OpenAIEmbeddings(api_key=openai_api_key)
    vectors = FAISS.from_documents(data, embeddings)

    # 3. ConversationalRetrievalChain êµ¬ì„±
    chain = ConversationalRetrievalChain.from_llm(
        llm=ChatOpenAI(model_name="gpt-4", temperature=0.0, api_key=openai_api_key),
        retriever=vectors.as_retriever()
    )

    # 4. ì‚¬ìš©ì ì§ˆë¬¸ ì²˜ë¦¬ í•¨ìˆ˜ ì •ì˜
    def conversational_chat(query):
        # ì„ íƒí•œ ì–¸ì–´ì— ë”°ë¼ GPT ì‘ë‹µ ì–¸ì–´ë¥¼ ëª…í™•íˆ ì§€ì‹œ
        if lang == "English":
            prompt = f"Regardless of the question language, please answer ONLY in English.\n\nUser: {query}"
        elif lang == "í•œêµ­ì–´":
            prompt = f"ì§ˆë¬¸ì´ ì–´ë–¤ ì–¸ì–´ë“  ê´€ê³„ì—†ì´ ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œë§Œ ë‹µë³€í•´ ì£¼ì„¸ìš”.\n\nì‚¬ìš©ì ì§ˆë¬¸: {query}"
        else:
            prompt = query  # ê¸°íƒ€ ì²˜ë¦¬ ì—†ì´ ê·¸ëŒ€ë¡œ ì „ë‹¬

        result = chain({
            "question": prompt,
            "chat_history": st.session_state["history"]
        })

        # ì›ë˜ ì‚¬ìš©ì ì…ë ¥ê³¼ GPT ì‘ë‹µì„ ëŒ€í™” ê¸°ë¡ì— ì €ì¥
        st.session_state["history"].append((query, result["answer"]))
        return result["answer"]

    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
    if "history" not in st.session_state:
        st.session_state["history"] = []
    if "generated" not in st.session_state:
        st.session_state["generated"] = [msg["init_greeting_bot"]]
    if "past" not in st.session_state:
        st.session_state["past"] = [msg["init_greeting_user"]]

    # ì‚¬ìš©ì ì…ë ¥ ì˜ì—­
    with st.container():
        with st.form(key="chat_form", clear_on_submit=True):
            user_input = st.text_input(msg["input_label"], placeholder=msg["input_placeholder"])
            submit_button = st.form_submit_button(label=msg["send_button"])

        if submit_button and user_input:
            output = conversational_chat(user_input)
            st.session_state["past"].append(user_input)
            st.session_state["generated"].append(output)

    # ëŒ€í™” íˆìŠ¤í† ë¦¬ ì¶œë ¥
    if st.session_state["generated"]:
        with st.container():
            for i in range(len(st.session_state["generated"])):
                message(st.session_state["past"][i], is_user=True, key=f"{i}_user", avatar_style="fun-emoji")
                message(st.session_state["generated"][i], key=f"{i}_bot", avatar_style="bottts")
